<!DOCTYPE html>
<html>
<head>
    <title>Real-time Speech Recognition and Text-to-Speech</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }

        h1 {
            color: #333;
            text-align: center;
        }

        #controlsContainer {
            text-align: center;
            margin: 20px 0;
        }

        #startButton {
            padding: 20px;
            background-color: #007bff;
            color: #fff;
            border: none;
            cursor: pointer;
            border-radius: 50%;
            width: 60px;
            height: 60px;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        #startButton.listening {
            background-color: #dc3545;
            animation: pulse 1.5s infinite;
        }

        #startButton:disabled {
            background-color: #6c757d;
            cursor: not-allowed;
            animation: none;
        }

        #status {
            margin-top: 20px;
            padding: 10px;
            border-radius: 5px;
            text-align: center;
            min-height: 20px;
        }

        .status-connected {
            background-color: #d4edda;
            color: #155724;
        }

        .status-error {
            background-color: #f8d7da;
            color: #721c24;
        }

        .status-connecting {
            background-color: #fff3cd;
            color: #856404;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }

        #conversation {
            margin-top: 20px;
            padding: 20px;
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
        }

        .message {
            margin: 10px 0;
            padding: 10px;
            border-radius: 5px;
        }

        .user-message {
            background-color: #e3f2fd;
            margin-left: 20%;
        }

        .assistant-message {
            background-color: #f5f5f5;
            margin-right: 20%;
        }
    </style>
</head>
<body>
    <h1>Voice Chat Assistant</h1>
    <div id="controlsContainer">
        <button id="startButton" title="Click to start/stop voice chat">
            ðŸŽ¤
        </button>
    </div>
    <p id="status"></p>
    <div id="conversation"></div>

    <script>
        const startButton = document.getElementById('startButton');
        const status = document.getElementById('status');
        const conversation = document.getElementById('conversation');
        let ws = null;
        let recognition = null;
        let isListening = false;
        let reconnectAttempts = 0;
        const MAX_RECONNECT_ATTEMPTS = 3;
        const RECONNECT_DELAY = 2000;
        
        // Generate a unique client ID
        const clientId = 'client-' + Math.random().toString(36).substr(2, 9);

        function updateStatus(message, type = 'info') {
            status.className = `status-${type}`;
            status.textContent = message;
        }

        function addMessageToConversation(text, isUser = false) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${isUser ? 'user-message' : 'assistant-message'}`;
            messageDiv.textContent = text;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }

        function setupSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window)) {
                updateStatus('Your browser does not support Web Speech API.', 'error');
                return null;
            }

            const recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                isListening = true;
                startButton.classList.add('listening');
                updateStatus('Listening... Speak into the microphone.', 'connected');
            };

            recognition.onresult = (event) => {
                const transcript = event.results[event.resultIndex][0].transcript;
                addMessageToConversation(transcript, true);
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({
                        type: 'message',
                        content: transcript,
                        clientId: clientId
                    }));
                }
            };

            recognition.onerror = (event) => {
                updateStatus(`Speech recognition error: ${event.error}`, 'error');
                stopRecognition();
            };

            recognition.onend = () => {
                if (isListening) {
                    recognition.start();
                }
            };

            return recognition;
        }

        function setupWebSocket() {
            if (ws) {
                ws.close();
            }

            ws = new WebSocket(`ws://127.0.0.1:8000/ws/${clientId}`);

            ws.onopen = () => {
                updateStatus('Connected to server', 'connected');
                reconnectAttempts = 0;
                startButton.disabled = false;
            };

            ws.onmessage = (event) => {
                try {
                    const data = JSON.parse(event.data);
                    if (data.type === 'text') {
                        addMessageToConversation(data.content);
                        speakText(data.content);
                    } else if (data.type === 'status') {
                        updateStatus(data.content, 'connected');
                    } else if (data.type === 'error') {
                        updateStatus(data.content, 'error');
                    }
                } catch (e) {
                    // Handle plain text responses for backward compatibility
                    addMessageToConversation(event.data);
                    speakText(event.data);
                }
            };

            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                updateStatus('Connection error. Retrying...', 'error');
            };

            ws.onclose = () => {
                updateStatus('Disconnected from server', 'error');
                stopRecognition();
                startButton.disabled = true;
                
                if (reconnectAttempts < MAX_RECONNECT_ATTEMPTS) {
                    reconnectAttempts++;
                    setTimeout(setupWebSocket, RECONNECT_DELAY);
                    updateStatus(`Reconnecting... Attempt ${reconnectAttempts}/${MAX_RECONNECT_ATTEMPTS}`, 'connecting');
                } else {
                    updateStatus('Could not connect to server. Please refresh the page.', 'error');
                }
            };
        }

        function speakText(text) {
            // Cancel any ongoing speech
            window.speechSynthesis.cancel();
            
            const speech = new SpeechSynthesisUtterance(text);
            speech.rate = 1.0;
            speech.pitch = 1.0;
            speech.volume = 1.0;
            
            window.speechSynthesis.speak(speech);
        }

        function startRecognition() {
            if (!recognition) {
                recognition = setupSpeechRecognition();
                if (!recognition) return;
            }
            
            try {
                recognition.start();
                isListening = true;
            } catch (error) {
                console.error('Recognition start error:', error);
                stopRecognition();
                recognition = setupSpeechRecognition();
                recognition.start();
            }
        }

        function stopRecognition() {
            if (recognition) {
                isListening = false;
                recognition.stop();
                startButton.classList.remove('listening');
                updateStatus('Voice recognition stopped', 'info');
            }
        }

        startButton.onclick = () => {
            if (!isListening) {
                if (!ws || ws.readyState !== WebSocket.OPEN) {
                    setupWebSocket();
                }
                startRecognition();
            } else {
                stopRecognition();
            }
        };

        // Setup WebSocket connection when page loads
        setupWebSocket();

        // Cleanup on page unload
        window.onbeforeunload = () => {
            if (recognition) {
                recognition.stop();
            }
            if (ws) {
                ws.close();
            }
        };
    </script>
</body>
</html>